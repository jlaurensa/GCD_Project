q()
temp = list.files(pattern="*.csv")
## The following two functions:
## 1.) makeCacheMatrix: This function creates a special "matrix" object that can cache its inverse.
## 2.) cacheSolve: This function computes the inverse of the special "matrix" returned
## by makeCacheMatrix above. If the inverse has already been calculated
## (and the matrix has not changed), then cacheSolve should retrieve the inverse
## from the cache.
## 1. makeCacheMatrix function, creates an object of the type list.
## It creates functions (or objects) used by cacheSolve() to get values
#  for x, or for i (inverse) and for setting the inverse of a matrix.
makeCacheMatrix <- function(x = matrix()) {
i <- NULL             # i stores the inverse of the matrix
set <- function(y) {  # resets to NULL every time the function is called
x <<- y
i <<- NULL
}
get <- function() x   # fn. returns the value of the matrix
setinverse <- function(inverse) i <<- inverse
getinverse <- function() i
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
## The second function, When called, it will see if the inverse of the matrix
## has been stored.
## If not, it will calculate the inverse of the matrix, store it and then return it.
## If the inverse for this object has been calculated and stored earlier,
## it will fetch the inverse and return it.
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
i <- x$getinverse()
if(!is.null(i)) {
message("getting cached data")
return(i)
}
data <- x$get()
i <- solve(data, ...)
x$setinverse(i)
i
}
x <- matrix(1:4, 2 ,2)
x
bigMat <- makeCacheMatrix(x)
bigMat$get()
bigMat$getinverse()
cacheSolve(bigMat)
cacheSolve(bigMat)
x <- rnorm(100, 2, 4)
summary(x)
str(x)
f <- gl(40,10)
str(f)
summary(f)
f
library(datasets)
head(airquality)
str(airquality)
m <- matrix(rnorm(100), 10, 10)
str(m)
m[,1]
s <- split(airquality, airquality$Month)
str(s)
s
str(ppois)
set.seed(20)
x <- rnorm(100)
e <- rnorm(100, 0, 2)
y <- 0.5 + x * 2 + e
summary(y)
plot(x,y)
set.seed(10)
x <- rbinom(100, 1, 0.5)
e <- rnorm(100, 0, 2)
y <- 0.5 + x * 2 + e
summary(y)
plot(x,y)
set.seed(1)
x <- rnorm(100)
log.mu <- 0.5 + 0.3 * x
y <- rpois(100, exp(log.mu))
summary(y)
plot(x,y)
set.seed(1)
sample(1:10, 4)
sample(letters, 5)
sample(letters, 5)
sample(1:10) ## permutation
sample(1:10, replace = TRUE) ## Sample w/replacement
4!
?factorial
set.seed(1)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
library(swirl)
swirl()
num_vect <- c(0.5, 55, -10, 6)
tf <- num_vect < 1
tf
num_vect >= 6
my_char <- c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
c(my_char, "Jose")
my_name <- c(my_char, "Jose")
my_name
paste(my_name, collapse = " ")
paste("Hello", "world", sep = " ")
paste("Hello", "world!", sep = " ")
paste(c(1:3), c("X", "Y", "Z"), sep = "")
paste(LETTERS, 1:4, sep = "-")
x <- c(44,NA,5,NA)
x * 3
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y, z), 100)
my_na <- is.na(my_data)
my_na
my_data ==NA
sum(my_na)
my_data
0/0
Inf-Inf
x
x[1:10]
x[is.na(x)]
nxt()
y <- x[!is.na(x)]
y
y[y > 0]
x[x > 0]
x[!is.na(x) & x > 0]
x(c[3,5,7])
x[c(3,5,7)]
x[0]
x[3000]
x[c(-2, -10)]
x[c(-2, -10)]
x[c(2, 10)]
x[-c(2, 10)] # es m√°s facil poner negativo el vector
vect <- c(foo = 11, bar = 2, norf = NA)
vect
names(vect)
vect2 <- c(11, 2, NA)
names(vect2) <- c("foo", "bar", "norf")
identical(vect, vect2)
vect["bar"]
vect[c("foo", "bar")]
my_vector <- c(1:20)
my_vector <- 1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector) <- c(4, 5)
dim(my_vector)
my_vector
attributes(my_vector)
my_vector
class(my_vector)
my_matrix <- my_vector
?matrix
my_matrix2 <- matrix(1:20, 4, 5)
identical(my_matrix, my_matrix2)
patients <- c("Bill","Gina", "Kelly", "Sean")
cbind(patients, my_matrix)
my_data <- data.frame(patients, my_matrix)
my_data
class(my_data)
cnames <- c("patient", "age", "weight", "bp", "rating","test")
colnames(my_data)
colnames(my_data) <- cnames
my_data
library(swirl)
install_from_swirl("R Programming Alt")
swirl()
library(swirl)
swril()
swirl()
head(flags)
dim(flags)
class(flags)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
cls_vect <- sapply(flags, class)
class(cls_vect)
View(flags)
sum(flags$orange)
flag_colors <- flags[,11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[,19:23]
View(flag_shapes)
lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6, 6))
unique_vals <- lapply(flags, unique())
unique_vals <- lapply(flags, unique)
unique_vals
sapply(unique_vals, length)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
install.packages("devtools", dependencies = TRUE)
install.packages("rcurl", dependencies = TRUE)
install.packages("Rcurl", dependencies = TRUE)
install.packages("Rcurl")
library(XML)
fileUrl <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE) #analizar el XML file "parse out"
xData <- getURL(fileUrl)
xData <- getURL(fileUrl)
?getURL
??getURL
install.packages("RCurl")
library(Rcurl)
library(RCurl)
library(XML)
fileUrl <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE) #analizar el XML file "parse out"
fileUrl <- "http://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE) #analizar el XML file "parse out"
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
rootNode[[2]]
rootNode[[1]][[1]]
xmlSApply(rootNode, xmlValue)
xpathSApply(rootNode,"//name",xmlValue)
xpathSApply(rootNode,"//price",xmlValue)
scores <- xpathSApply(doc,"//li[@class='score']",xmlValue) #list items
scores
install.packages("jsonlite")
library(jsonlite)
jsonData <- fromJSON("https://api.github.com/users/jtleek/repos")
View(jsonData)
names(jsonData)
names(jsonData$owner)
names(jsonData$owner$login)
myjson <- toJSON(iris, pretty = TRUE)
cat(myjason)
cat(myjson)
View(jsonData)
iris2 <- fromJSON(myjson)
head(iris2)
library(data.table)
install.packages("data.table")
library(data.table)
library(data.table)
DF = data.frame(x=rnorm(9),y=rep(c("a","b","c"),each=3),z=rnorm(9))
head(DF,3)
DT = data.table(x=rnorm(9),y=rep(c("a","b","c"),each=3),z=rnorm(9))
head(DT,3)
tables()
DT[2,] #subsetting rows
DT[DT$y="a",]
DT[DT$y=="a",]
pollution <- read.csv("data/avgpm25.csv", colClasses = c("numeric", "character",
"factor", "numeric", "numeric"))
head(pollution)
pollution <- read.csv("data/avgpm25.csv", colClasses = c("numeric", "character",
"factor", "numeric", "numeric"))
library(datasets)
pollution <- read.csv("data/avgpm25.csv", colClasses = c("numeric", "character",
"factor", "numeric", "numeric"))
library(airquality)
datasets(airquality)
dataset(airquality)
library(datasets)
head(airquality)
head(avgpm25)
head(pollution)
?par
library(datasets)
data(cars)
library(datasets)
data(cars)
?with
cars
with(cars,plot(speed,dis))
with(cars,plot(speed,dist))
with(cars,plot(dist,speed))
library(lattice)
lattice
state <- data.frame(state.x77, region = state.region)
View(state)
xyplot(Life.Exp ~ Income | region, data = state, layout = c(4,1))
View(state)
# GGPLOT2
library(ggplot2)
data(mpg)
qplot(displ, hwy, data = mpg)
library(ggplot2)
install.packages(ggplot2)
install.packages("ggplot2")
data(mpg)
library(datasets)
data(mpg)
library(lattice)
library(datasets)
xyplot(Ozone ~ Wind, data = airquality)
airquality <- transform(airquality, Month = factor(Month))
View(airquality)
xyplot(Ozone ~ Wind | Month, data = airquality, layout = c(5,1))
xyplot(Ozone ~ Wind | Month, data = airquality, layout = c(1,5))
xyplot(Ozone ~ Wind | Month, data = airquality, layout = c(5,1))
set.seed(10)
x <- rnorm(100)
f <- rep(0:1, each = 50)
y <- x + f - f * x + rnorm(100, sd = 0.5)
f <- factor(f, labels = c("Group 1", "Group 2"))
set.seed(10)
x <- rnorm(100)
f <- rep(0:1, each = 50)
y <- x + f - f * x + rnorm(100, sd = 0.5)
f <- factor(f, labels = c("Group 1", "Group 2"))
xyplot(y ~ x | f, layout = c(2,1))
xyplot(y ~ x | f, panel = function(x, y, ...){
panel.xyplot(x, y, ...) ##First call the default panel function for xyplot
panel.abline(h = median(y), lty = 2) ## add horizontal line at the median
})
xyplot(y ~ x | f, panel = function(x, y, ...){
panel.xyplot(x, y, ...) ##First call the default panel function for xyplot
panel.lmline(x, y, col = 2) ## add horizontal line at the median
})
library(ggplot2)
str(mpg)
qplot(displ, hwy, data = mpg)
qplot(displ, hwy, data = mpg, color = drv)
qplot(displ, hwy, data = mpg, geom = c("point", "smooth"))
qplot(displ, hwy, data = mpg, fill = drv )
qplot(hwy, data = mpg, fill = drv ) #histogram
qplot(displ, hwy, data = mpg, facets = .~drv)
qplot(hwy, data = mpg, facets = drv~., binwidth = 2)
str(maacs)
library(datasets)
str(maacs)
library(ggplot2)
?geom
??geom
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
?splom
library(datasets)
data(airquality)
library(datasets)
data(airquality)
library(ggplot2)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
ggplot(movies, aes(votes, rating))
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies) + stats_smooth("loess")
?par
?splom
?trellis.par.set
setwd("~/Coursera/Data_Science/Getting_Cleaning_Data/UCI HAR Dataset")
features <- read.csv("features.txt", header = FALSE, sep = "")
## Read all the training data
setwd("~/Coursera/Data_Science/Getting_Cleaning_Data/UCI HAR Dataset/train")
x_train <- read.csv("X_train.txt", header = FALSE, sep = "")
sub_train <- read.csv("subject_train.txt", header = FALSE)
y_train <- read.csv("Y_train.txt", header = FALSE)
## Merges all the training data
train_data <- cbind(x_train, sub_train, y_train)
## Read all the test data
setwd("~/Coursera/Data_Science/Getting_Cleaning_Data/UCI HAR Dataset/test")
x_test <- read.csv("X_test.txt", header = FALSE, sep = "")
sub_test <- read.csv("subject_test.txt", header = FALSE)
y_test <- read.csv("Y_test.txt", header = FALSE)
## Merges all the test data
test_data <- cbind(x_test, sub_test, y_test)
## Merges the training and the test sets to create one data set
merge <- rbind(train_data, test_data)
## Assigns the feature vector to the merged data as column names,
## as well as the subject and activity.
colnames(merge) <- features[,2]
colnames(merge)[562:563] <- c("Subject","Activity")
## Reading and loading the activity_labels.txt
setwd("~/Coursera/Data_Science/Getting_Cleaning_Data/UCI HAR Dataset")
act_labels <- read.csv("activity_labels.txt", header = FALSE, sep = "")
colnames(act_labels) <- c("Code","Activity")
act_labels$Activity <- as.character(act_labels$Activity)
Activity <- c(act_labels$Activity)
## Replace specified values with new values, in a vector or factor;
## Uses descriptive activity names to name the activities in the data set
library(plyr)
merge$Activity <- mapvalues(merge$Activity, from = c(1:6), to = Activity)
## or I could use.
# mapvalues(merge$Activity, from = c(1:6),
#          to = c("WALKING", "WALKING_UPSTAIRS", "WALKING_DOWNSTAIRS", "SITTING",
#                 "STANDING", "LAYING"))
## Writing the Tidy Data set, into a txt file, within the "right folder"
## Sets the working directory..
setwd("~/Coursera/Data_Science/Getting_Cleaning_Data/GCD_Project")
## Reads the tidy data set..
Human_Rec_TidyData <- read.csv("Human Act Recognition Tidy data set.txt", sep = "",
header = TRUE)
## Extracts the needed measurements..
mean_measure <- Human_Rec_TidyData[ , grepl( "mean()" , names(Human_Rec_TidyData))]
std_measure <- Human_Rec_TidyData[ , grepl( "std()" , names(Human_Rec_TidyData))]
## Merges the measurement sets...
extracted_measures <- cbind(mean_measure, std_measure)
## Sets the working directory..
setwd("~/Coursera/Data_Science/Getting_Cleaning_Data/GCD_Project")
## Reads the tidy data set..
Human_Rec_TidyData <- read.csv("Human Act Recognition Tidy data set.txt", sep = "",
header = TRUE)
## merges the [Point 2] measurements with subject and activity
Subject <- Human_Rec_TidyData$Subject
Activity <- Human_Rec_TidyData$Activity
mean_measure <- Human_Rec_TidyData[ , grepl( "mean()" , names(Human_Rec_TidyData))]
avg_act_subj <- cbind(Subject, Activity, mean_measure)
avg_act_subj$Activity <- as.character(avg_act_subj$Activity)
## creates a second, independent tidy data set with the average of each variable
# for each activity and each subjec
filter <- ddply(avg_act_subj, .(Subject, Activity), colwise(mean))
## Writing the Tidy Data set, into a txt file, within the "right folder"
setwd("~/Coursera/Data_Science/Getting_Cleaning_Data/GCD_Project")
write.table(filter, file = "Avg_variables_subjects.txt", row.name = FALSE)
tabla <- read.csv("Avg_variables_subjects.txt", sep = "")
View(tabla)
